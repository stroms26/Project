{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e8a73a1d",
      "metadata": {},
      "source": [
        "# NYC Weather Data Cleaning Pipeline\n",
        "\n",
        "This notebook cleans and prepares NYC weather data (2016-2022) for merging with Citi Bike trip data. The pipeline includes:\n",
        "- Downloading data from Kaggle\n",
        "- Standardizing column names\n",
        "- Filtering for year 2018\n",
        "- Handling missing values\n",
        "- Creating derived features\n",
        "- Merging with Citi Bike data\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1: Import Libraries and Download Dataset\n",
        "\n",
        "Import necessary Python libraries (`kagglehub`, `pandas`, `os`) and download the NYC Weather dataset (2016-2022) from Kaggle using the `kagglehub` API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9ef1fdf5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /Users/hstro/.cache/kagglehub/datasets/aadimator/nyc-weather-2016-to-2022/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"aadimator/nyc-weather-2016-to-2022\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86cbc62e",
      "metadata": {},
      "source": [
        "## Step 2: Load the Weather CSV File\n",
        "\n",
        "Load the downloaded CSV file into a pandas DataFrame. This cell:\n",
        "- Lists all CSV files in the download directory\n",
        "- Loads the weather data file\n",
        "- Displays the dataset shape, column names, and first few rows for initial inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4abc16e6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found CSV files: ['NYC_Weather_2016_2022.csv']\n",
            "\n",
            "Original dataset shape: (59760, 10)\n",
            "\n",
            "Original column names:\n",
            "['time', 'temperature_2m (°C)', 'precipitation (mm)', 'rain (mm)', 'cloudcover (%)', 'cloudcover_low (%)', 'cloudcover_mid (%)', 'cloudcover_high (%)', 'windspeed_10m (km/h)', 'winddirection_10m (°)']\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>temperature_2m (°C)</th>\n",
              "      <th>precipitation (mm)</th>\n",
              "      <th>rain (mm)</th>\n",
              "      <th>cloudcover (%)</th>\n",
              "      <th>cloudcover_low (%)</th>\n",
              "      <th>cloudcover_mid (%)</th>\n",
              "      <th>cloudcover_high (%)</th>\n",
              "      <th>windspeed_10m (km/h)</th>\n",
              "      <th>winddirection_10m (°)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-01T00:00</td>\n",
              "      <td>7.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>296.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-01T01:00</td>\n",
              "      <td>7.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>9.8</td>\n",
              "      <td>287.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-01T02:00</td>\n",
              "      <td>7.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>9.7</td>\n",
              "      <td>285.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-01T03:00</td>\n",
              "      <td>6.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>9.2</td>\n",
              "      <td>281.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-01T04:00</td>\n",
              "      <td>6.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>279.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               time  temperature_2m (°C)  precipitation (mm)  rain (mm)  \\\n",
              "0  2016-01-01T00:00                  7.6                 0.0        0.0   \n",
              "1  2016-01-01T01:00                  7.5                 0.0        0.0   \n",
              "2  2016-01-01T02:00                  7.1                 0.0        0.0   \n",
              "3  2016-01-01T03:00                  6.6                 0.0        0.0   \n",
              "4  2016-01-01T04:00                  6.3                 0.0        0.0   \n",
              "\n",
              "   cloudcover (%)  cloudcover_low (%)  cloudcover_mid (%)  \\\n",
              "0            69.0                53.0                 0.0   \n",
              "1            20.0                 4.0                 0.0   \n",
              "2            32.0                 3.0                 0.0   \n",
              "3            35.0                 5.0                 0.0   \n",
              "4            34.0                 4.0                 0.0   \n",
              "\n",
              "   cloudcover_high (%)  windspeed_10m (km/h)  winddirection_10m (°)  \n",
              "0                 72.0                  10.0                  296.0  \n",
              "1                 56.0                   9.8                  287.0  \n",
              "2                 99.0                   9.7                  285.0  \n",
              "3                100.0                   9.2                  281.0  \n",
              "4                100.0                   9.1                  279.0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the weather data\n",
        "csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
        "print(f\"Found CSV files: {csv_files}\")\n",
        "\n",
        "# Load the data (assuming there's one main CSV file)\n",
        "weather_file = os.path.join(path, csv_files[0])\n",
        "df = pd.read_csv(weather_file)\n",
        "\n",
        "print(f\"\\nOriginal dataset shape: {df.shape}\")\n",
        "print(f\"\\nOriginal column names:\")\n",
        "print(df.columns.tolist())\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90d29cf7",
      "metadata": {},
      "source": [
        "## Step 3: Standardize Column Names\n",
        "\n",
        "Clean up column names by:\n",
        "- Converting all names to lowercase\n",
        "- Replacing spaces with underscores\n",
        "\n",
        "This ensures consistent naming conventions throughout the analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4bd8e13d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standardized column names:\n",
            "['time', 'temperature_2m_(°c)', 'precipitation_(mm)', 'rain_(mm)', 'cloudcover_(%)', 'cloudcover_low_(%)', 'cloudcover_mid_(%)', 'cloudcover_high_(%)', 'windspeed_10m_(km/h)', 'winddirection_10m_(°)']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>temperature_2m_(°c)</th>\n",
              "      <th>precipitation_(mm)</th>\n",
              "      <th>rain_(mm)</th>\n",
              "      <th>cloudcover_(%)</th>\n",
              "      <th>cloudcover_low_(%)</th>\n",
              "      <th>cloudcover_mid_(%)</th>\n",
              "      <th>cloudcover_high_(%)</th>\n",
              "      <th>windspeed_10m_(km/h)</th>\n",
              "      <th>winddirection_10m_(°)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-01T00:00</td>\n",
              "      <td>7.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>296.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-01T01:00</td>\n",
              "      <td>7.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>9.8</td>\n",
              "      <td>287.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-01T02:00</td>\n",
              "      <td>7.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>9.7</td>\n",
              "      <td>285.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-01T03:00</td>\n",
              "      <td>6.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>9.2</td>\n",
              "      <td>281.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-01T04:00</td>\n",
              "      <td>6.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>279.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               time  temperature_2m_(°c)  precipitation_(mm)  rain_(mm)  \\\n",
              "0  2016-01-01T00:00                  7.6                 0.0        0.0   \n",
              "1  2016-01-01T01:00                  7.5                 0.0        0.0   \n",
              "2  2016-01-01T02:00                  7.1                 0.0        0.0   \n",
              "3  2016-01-01T03:00                  6.6                 0.0        0.0   \n",
              "4  2016-01-01T04:00                  6.3                 0.0        0.0   \n",
              "\n",
              "   cloudcover_(%)  cloudcover_low_(%)  cloudcover_mid_(%)  \\\n",
              "0            69.0                53.0                 0.0   \n",
              "1            20.0                 4.0                 0.0   \n",
              "2            32.0                 3.0                 0.0   \n",
              "3            35.0                 5.0                 0.0   \n",
              "4            34.0                 4.0                 0.0   \n",
              "\n",
              "   cloudcover_high_(%)  windspeed_10m_(km/h)  winddirection_10m_(°)  \n",
              "0                 72.0                  10.0                  296.0  \n",
              "1                 56.0                   9.8                  287.0  \n",
              "2                 99.0                   9.7                  285.0  \n",
              "3                100.0                   9.2                  281.0  \n",
              "4                100.0                   9.1                  279.0  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 1: Standardize column names (lowercase and replace spaces with underscores)\n",
        "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "\n",
        "print(\"Standardized column names:\")\n",
        "print(df.columns.tolist())\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5480ee6",
      "metadata": {},
      "source": [
        "## Step 4: Filter for Year 2018\n",
        "\n",
        "Since our Citi Bike data is from 2018, we filter the weather dataset to keep only records from year 2018. This cell:\n",
        "- Identifies the date column (`time`)\n",
        "- Converts it to datetime format\n",
        "- Filters rows to retain only 2018 data (reduces from ~60,000 to ~8,760 rows - one hourly reading per hour of the year)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b2414361",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Date-related columns found: ['time']\n",
            "\n",
            "Filtered from 59760 rows to 8760 rows (year 2018 only)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>temperature_2m_(°c)</th>\n",
              "      <th>precipitation_(mm)</th>\n",
              "      <th>rain_(mm)</th>\n",
              "      <th>cloudcover_(%)</th>\n",
              "      <th>cloudcover_low_(%)</th>\n",
              "      <th>cloudcover_mid_(%)</th>\n",
              "      <th>cloudcover_high_(%)</th>\n",
              "      <th>windspeed_10m_(km/h)</th>\n",
              "      <th>winddirection_10m_(°)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17544</th>\n",
              "      <td>2018-01-01 00:00:00</td>\n",
              "      <td>-11.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>302.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17545</th>\n",
              "      <td>2018-01-01 01:00:00</td>\n",
              "      <td>-11.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.1</td>\n",
              "      <td>297.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17546</th>\n",
              "      <td>2018-01-01 02:00:00</td>\n",
              "      <td>-11.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.3</td>\n",
              "      <td>302.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17547</th>\n",
              "      <td>2018-01-01 03:00:00</td>\n",
              "      <td>-12.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>307.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17548</th>\n",
              "      <td>2018-01-01 04:00:00</td>\n",
              "      <td>-12.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.3</td>\n",
              "      <td>309.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     time  temperature_2m_(°c)  precipitation_(mm)  rain_(mm)  \\\n",
              "17544 2018-01-01 00:00:00                -11.1                 0.0        0.0   \n",
              "17545 2018-01-01 01:00:00                -11.5                 0.0        0.0   \n",
              "17546 2018-01-01 02:00:00                -11.8                 0.0        0.0   \n",
              "17547 2018-01-01 03:00:00                -12.2                 0.0        0.0   \n",
              "17548 2018-01-01 04:00:00                -12.2                 0.0        0.0   \n",
              "\n",
              "       cloudcover_(%)  cloudcover_low_(%)  cloudcover_mid_(%)  \\\n",
              "17544             0.0                 0.0                 0.0   \n",
              "17545             0.0                 0.0                 0.0   \n",
              "17546             0.0                 0.0                 0.0   \n",
              "17547             0.0                 0.0                 0.0   \n",
              "17548             0.0                 0.0                 0.0   \n",
              "\n",
              "       cloudcover_high_(%)  windspeed_10m_(km/h)  winddirection_10m_(°)  \n",
              "17544                  0.0                   9.4                  302.0  \n",
              "17545                  0.0                  10.1                  297.0  \n",
              "17546                  0.0                  12.3                  302.0  \n",
              "17547                  0.0                  13.9                  307.0  \n",
              "17548                  0.0                  14.3                  309.0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 2: Keep only rows from year 2018\n",
        "# First, identify the date column\n",
        "date_columns = [col for col in df.columns if 'date' in col or 'time' in col]\n",
        "print(f\"Date-related columns found: {date_columns}\")\n",
        "\n",
        "# Convert date column to datetime\n",
        "if date_columns:\n",
        "    date_col = date_columns[0]\n",
        "    df[date_col] = pd.to_datetime(df[date_col])\n",
        "    \n",
        "    # Filter for year 2018\n",
        "    initial_rows = len(df)\n",
        "    df = df[df[date_col].dt.year == 2018].copy()\n",
        "    print(f\"\\nFiltered from {initial_rows} rows to {len(df)} rows (year 2018 only)\")\n",
        "else:\n",
        "    print(\"Warning: No date column found!\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e56a50fb",
      "metadata": {},
      "source": [
        "## Step 5: Identify Weather Columns and Check Missing Values\n",
        "\n",
        "Identify the key weather columns needed for analysis:\n",
        "- **Temperature**: `temperature_2m_(°c)`\n",
        "- **Precipitation**: `precipitation_(mm)`\n",
        "- **Wind Speed**: `windspeed_10m_(km/h)`\n",
        "\n",
        "Check for missing values in these essential columns before proceeding with cleaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "30738ef6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Identified weather columns:\n",
            "  Temperature: temperature_2m_(°c)\n",
            "  Precipitation: precipitation_(mm)\n",
            "  Wind: windspeed_10m_(km/h)\n",
            "\n",
            "Missing values before cleaning:\n",
            "  temperature_2m_(°c): 0\n",
            "  precipitation_(mm): 0\n",
            "  windspeed_10m_(km/h): 0\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Identify weather columns and check for missing values\n",
        "# Find temperature, precipitation, and wind columns\n",
        "temp_col = None\n",
        "precip_col = None\n",
        "wind_col = None\n",
        "\n",
        "for col in df.columns:\n",
        "    if 'temp' in col and not 'min' in col and not 'max' in col:\n",
        "        temp_col = col\n",
        "    elif 'precip' in col:\n",
        "        precip_col = col\n",
        "    elif 'wind' in col and 'speed' in col:\n",
        "        wind_col = col\n",
        "    elif 'wind' in col and wind_col is None:\n",
        "        wind_col = col\n",
        "\n",
        "print(\"Identified weather columns:\")\n",
        "print(f\"  Temperature: {temp_col}\")\n",
        "print(f\"  Precipitation: {precip_col}\")\n",
        "print(f\"  Wind: {wind_col}\")\n",
        "\n",
        "# Display missing values\n",
        "print(\"\\nMissing values before cleaning:\")\n",
        "if temp_col:\n",
        "    print(f\"  {temp_col}: {df[temp_col].isna().sum()}\")\n",
        "if precip_col:\n",
        "    print(f\"  {precip_col}: {df[precip_col].isna().sum()}\")\n",
        "if wind_col:\n",
        "    print(f\"  {wind_col}: {df[wind_col].isna().sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1f4bd2f",
      "metadata": {},
      "source": [
        "## Step 6: Remove Rows with Missing Weather Values\n",
        "\n",
        "Remove any rows that have missing values in the essential weather columns (temperature, precipitation, wind speed). This ensures data quality for the analysis. Also display the valid range of values for each weather variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2f62d762",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed 0 rows with missing weather values\n",
            "Remaining rows: 8760\n",
            "\n",
            "Temperature range: -18.3 to 34.5\n",
            "Precipitation range: 0.0 to 6.8\n",
            "Wind range: 0.4 to 45.3\n"
          ]
        }
      ],
      "source": [
        "# Step 3 (continued): Remove rows with missing essential weather values\n",
        "initial_rows = len(df)\n",
        "\n",
        "# Drop rows with missing values in essential columns\n",
        "essential_cols = [col for col in [temp_col, precip_col, wind_col] if col is not None]\n",
        "df = df.dropna(subset=essential_cols)\n",
        "\n",
        "print(f\"Removed {initial_rows - len(df)} rows with missing weather values\")\n",
        "print(f\"Remaining rows: {len(df)}\")\n",
        "\n",
        "# Check for and remove obviously invalid values (e.g., extreme outliers)\n",
        "if temp_col:\n",
        "    print(f\"\\nTemperature range: {df[temp_col].min()} to {df[temp_col].max()}\")\n",
        "if precip_col:\n",
        "    print(f\"Precipitation range: {df[precip_col].min()} to {df[precip_col].max()}\")\n",
        "if wind_col:\n",
        "    print(f\"Wind range: {df[wind_col].min()} to {df[wind_col].max()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e6766d2",
      "metadata": {},
      "source": [
        "## Step 7: Temperature Unit Check\n",
        "\n",
        "Verify that temperature is in Celsius. The check compares the mean temperature against typical NYC ranges:\n",
        "- **Celsius**: Mean ~12°C (range: -18°C to 35°C)\n",
        "- **Fahrenheit**: Mean ~54°F (range: 14°F to 95°F)\n",
        "\n",
        "If the mean is above 40, it's likely in Fahrenheit and needs conversion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ee873bc2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Temperature statistics:\n",
            "  Mean: 12.76\n",
            "  Max: 34.50\n",
            "  Min: -18.30\n",
            "\n",
            "✓ Temperature already in Celsius\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Convert temperature to Celsius if needed\n",
        "if temp_col:\n",
        "    # Check if temperature is in Fahrenheit\n",
        "    # NYC typical temperature range:\n",
        "    # - Celsius: -10 to 35°C\n",
        "    # - Fahrenheit: 14 to 95°F\n",
        "    \n",
        "    temp_mean = df[temp_col].mean()\n",
        "    temp_max = df[temp_col].max()\n",
        "    \n",
        "    print(f\"\\nTemperature statistics:\")\n",
        "    print(f\"  Mean: {temp_mean:.2f}\")\n",
        "    print(f\"  Max: {temp_max:.2f}\")\n",
        "    print(f\"  Min: {df[temp_col].min():.2f}\")\n",
        "    \n",
        "    # If mean temperature is above 40, likely Fahrenheit\n",
        "    if temp_mean > 40:\n",
        "        print(\"\\n✓ Detected Fahrenheit - Converting to Celsius...\")\n",
        "        df[temp_col] = (df[temp_col] - 32) * 5/9\n",
        "        print(f\"  New mean temperature: {df[temp_col].mean():.2f}°C\")\n",
        "        print(f\"  New range: {df[temp_col].min():.2f}°C to {df[temp_col].max():.2f}°C\")\n",
        "    else:\n",
        "        print(\"\\n✓ Temperature already in Celsius\")\n",
        "else:\n",
        "    print(\"Warning: No temperature column found for conversion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af904e53",
      "metadata": {},
      "source": [
        "## Step 8: Clean Precipitation Data\n",
        "\n",
        "Process the precipitation column to create a standardized `precip_mm` column. This step handles both:\n",
        "- **Numeric data**: Already in mm, create standardized column\n",
        "- **Categorical data**: Create binary `rain_flag` indicator\n",
        "\n",
        "The output shows precipitation statistics including range, mean, and number of days with precipitation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "57781bb2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "PRECIPITATION CLEANING\n",
            "============================================================\n",
            "\n",
            "Analyzing precipitation column: precipitation_(mm)\n",
            "Data type: float64\n",
            "\n",
            "Sample values:\n",
            "17544    0.0\n",
            "17545    0.0\n",
            "17546    0.0\n",
            "17547    0.0\n",
            "17548    0.0\n",
            "17549    0.0\n",
            "17550    0.0\n",
            "17551    0.0\n",
            "17552    0.0\n",
            "17553    0.0\n",
            "Name: precipitation_(mm), dtype: float64\n",
            "\n",
            "✓ Detected NUMERIC precipitation data\n",
            "  Created 'precip_mm' column\n",
            "  Range: 0.00 to 6.80 mm\n",
            "  Mean: 0.16 mm\n",
            "  Days with precipitation > 0: 1568\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Clean precipitation column\n",
        "print(\"=\"*60)\n",
        "print(\"PRECIPITATION CLEANING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if precip_col:\n",
        "    print(f\"\\nAnalyzing precipitation column: {precip_col}\")\n",
        "    print(f\"Data type: {df[precip_col].dtype}\")\n",
        "    print(f\"\\nSample values:\")\n",
        "    print(df[precip_col].head(10))\n",
        "    \n",
        "    # Check if precipitation is numeric or categorical\n",
        "    if pd.api.types.is_numeric_dtype(df[precip_col]):\n",
        "        # Case 5a: Numeric precipitation\n",
        "        print(\"\\n✓ Detected NUMERIC precipitation data\")\n",
        "        \n",
        "        # Standardize to millimeters\n",
        "        df[\"precip_mm\"] = pd.to_numeric(df[precip_col], errors=\"coerce\").fillna(0)\n",
        "        \n",
        "        print(f\"  Created 'precip_mm' column\")\n",
        "        print(f\"  Range: {df['precip_mm'].min():.2f} to {df['precip_mm'].max():.2f} mm\")\n",
        "        print(f\"  Mean: {df['precip_mm'].mean():.2f} mm\")\n",
        "        print(f\"  Days with precipitation > 0: {(df['precip_mm'] > 0).sum()}\")\n",
        "        \n",
        "    else:\n",
        "        # Case 5b: Categorical precipitation\n",
        "        print(\"\\n✓ Detected CATEGORICAL precipitation data\")\n",
        "        print(f\"\\nUnique values: {df[precip_col].unique()}\")\n",
        "        \n",
        "        # Create rain flag\n",
        "        df[\"rain_flag\"] = df[precip_col].astype(str).str.lower().str.contains(\"rain\", na=False).astype(int)\n",
        "        print(f\"  Created 'rain_flag' column\")\n",
        "        print(f\"  Days with rain: {df['rain_flag'].sum()}\")\n",
        "        \n",
        "        # Create snow flag if snow is present\n",
        "        if df[precip_col].astype(str).str.lower().str.contains(\"snow\", na=False).any():\n",
        "            df[\"snow_flag\"] = df[precip_col].astype(str).str.lower().str.contains(\"snow\", na=False).astype(int)\n",
        "            print(f\"  Created 'snow_flag' column\")\n",
        "            print(f\"  Days with snow: {df['snow_flag'].sum()}\")\n",
        "        \n",
        "        # Also check for weather_condition column if it exists\n",
        "        weather_cond_cols = [col for col in df.columns if 'weather' in col and 'condition' in col]\n",
        "        if weather_cond_cols:\n",
        "            weather_col = weather_cond_cols[0]\n",
        "            print(f\"\\n  Found additional weather condition column: {weather_col}\")\n",
        "            \n",
        "            # Create additional flags from weather_condition if not already created\n",
        "            if 'rain_flag' not in df.columns or df['rain_flag'].sum() == 0:\n",
        "                df[\"rain_flag\"] = df[weather_col].astype(str).str.lower().str.contains(\"rain\", na=False).astype(int)\n",
        "                print(f\"  Updated 'rain_flag' from {weather_col}\")\n",
        "                print(f\"  Days with rain: {df['rain_flag'].sum()}\")\n",
        "            \n",
        "            if 'snow_flag' not in df.columns and df[weather_col].astype(str).str.lower().str.contains(\"snow\", na=False).any():\n",
        "                df[\"snow_flag\"] = df[weather_col].astype(str).str.lower().str.contains(\"snow\", na=False).astype(int)\n",
        "                print(f\"  Created 'snow_flag' from {weather_col}\")\n",
        "                print(f\"  Days with snow: {df['snow_flag'].sum()}\")\n",
        "else:\n",
        "    print(\"\\nWarning: No precipitation column found!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2f3c7a1",
      "metadata": {},
      "source": [
        "## Step 9: Clean Wind Speed Data\n",
        "\n",
        "Process wind speed data and standardize to km/h. The cell:\n",
        "- Converts wind speed to numeric format\n",
        "- Checks if data is in mph (mean < 25) or km/h (mean ≥ 25)\n",
        "- Converts from mph to km/h if necessary (multiply by 1.60934)\n",
        "- Creates standardized `wind_kmh` column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c5d31b74",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "WIND SPEED CLEANING\n",
            "============================================================\n",
            "\n",
            "Analyzing wind column: windspeed_10m_(km/h)\n",
            "Data type: float64\n",
            "\n",
            "Wind speed statistics:\n",
            "  Mean: 11.46\n",
            "  Max: 45.30\n",
            "  Min: 0.40\n",
            "\n",
            "✓ Detected mph - Converting to km/h...\n",
            "  Created 'wind_kmh' column\n",
            "  New mean: 18.45 km/h\n",
            "  New range: 0.64 to 72.90 km/h\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Clean wind speed\n",
        "print(\"=\"*60)\n",
        "print(\"WIND SPEED CLEANING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if wind_col:\n",
        "    print(f\"\\nAnalyzing wind column: {wind_col}\")\n",
        "    print(f\"Data type: {df[wind_col].dtype}\")\n",
        "    \n",
        "    # Ensure wind speed is numeric\n",
        "    df[\"wind_speed\"] = pd.to_numeric(df[wind_col], errors=\"coerce\")\n",
        "    \n",
        "    # Remove any NaN values that resulted from conversion\n",
        "    nan_count = df[\"wind_speed\"].isna().sum()\n",
        "    if nan_count > 0:\n",
        "        print(f\"  Converted {nan_count} non-numeric values to NaN\")\n",
        "        df = df.dropna(subset=[\"wind_speed\"])\n",
        "        print(f\"  Removed rows with invalid wind speed\")\n",
        "    \n",
        "    # Check units and convert to km/h if needed\n",
        "    wind_mean = df[\"wind_speed\"].mean()\n",
        "    wind_max = df[\"wind_speed\"].max()\n",
        "    \n",
        "    print(f\"\\nWind speed statistics:\")\n",
        "    print(f\"  Mean: {wind_mean:.2f}\")\n",
        "    print(f\"  Max: {wind_max:.2f}\")\n",
        "    print(f\"  Min: {df['wind_speed'].min():.2f}\")\n",
        "    \n",
        "    # NYC typical wind speed:\n",
        "    # - mph: average around 10-15 mph, rarely exceeds 40 mph\n",
        "    # - km/h: average around 16-24 km/h, rarely exceeds 65 km/h\n",
        "    \n",
        "    if wind_mean < 25:  # Likely in mph\n",
        "        print(\"\\n✓ Detected mph - Converting to km/h...\")\n",
        "        df[\"wind_kmh\"] = df[\"wind_speed\"] * 1.60934\n",
        "        print(f\"  Created 'wind_kmh' column\")\n",
        "        print(f\"  New mean: {df['wind_kmh'].mean():.2f} km/h\")\n",
        "        print(f\"  New range: {df['wind_kmh'].min():.2f} to {df['wind_kmh'].max():.2f} km/h\")\n",
        "    else:\n",
        "        print(\"\\n✓ Already in km/h - Renaming column...\")\n",
        "        df.rename(columns={\"wind_speed\": \"wind_kmh\"}, inplace=True)\n",
        "        print(f\"  Renamed to 'wind_kmh'\")\n",
        "        print(f\"  Range: {df['wind_kmh'].min():.2f} to {df['wind_kmh'].max():.2f} km/h\")\n",
        "else:\n",
        "    print(\"\\nWarning: No wind column found!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2683109",
      "metadata": {},
      "source": [
        "## Step 10: Create Derived Feature Columns\n",
        "\n",
        "Create additional features useful for analysis:\n",
        "\n",
        "1. **`temp_bin`**: Temperature categories (<0°C, 0-10°C, 10-20°C, 20-30°C, >30°C)\n",
        "2. **`rain_flag`**: Binary indicator (1 = precipitation > 0mm, 0 = no rain)\n",
        "3. **`month`**: Extracted month number (1-12)\n",
        "4. **`season`**: Categorical season (Winter, Spring, Summer, Autumn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3cb32832",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "CREATING DERIVED COLUMNS\n",
            "============================================================\n",
            "\n",
            "✓ Created 'temp_bin' column\n",
            "  Temperature distribution:\n",
            "temp_bin\n",
            "<0°C        842\n",
            "0–10°C     3052\n",
            "10–20°C    2092\n",
            "20–30°C    2596\n",
            ">30°C       178\n",
            "Name: count, dtype: int64\n",
            "\n",
            "✓ Created 'rain_flag' from numeric precipitation\n",
            "  Days with rain (precip > 0 mm): 1568\n",
            "  Days without rain: 7192\n",
            "\n",
            "✓ Created 'month' column\n",
            "✓ Created 'season' column\n",
            "  Seasonal distribution:\n",
            "season\n",
            "Winter    2160\n",
            "Spring    2184\n",
            "Summer    2208\n",
            "Autumn    2208\n",
            "Name: count, dtype: int64\n",
            "\n",
            "============================================================\n",
            "\n",
            "New derived columns added:\n",
            "  - temp_bin\n",
            "  - rain_flag\n",
            "  - month\n",
            "  - season\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Create useful derived columns\n",
        "print(\"=\"*60)\n",
        "print(\"CREATING DERIVED COLUMNS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Temperature bins\n",
        "if temp_col:\n",
        "    # Use the temperature column (already converted to Celsius)\n",
        "    temp_column_to_use = temp_col\n",
        "    \n",
        "    df[\"temp_bin\"] = pd.cut(\n",
        "        df[temp_column_to_use],\n",
        "        bins=[-50, 0, 10, 20, 30, 50],\n",
        "        labels=[\"<0°C\", \"0–10°C\", \"10–20°C\", \"20–30°C\", \">30°C\"]\n",
        "    )\n",
        "    \n",
        "    print(\"\\n✓ Created 'temp_bin' column\")\n",
        "    print(f\"  Temperature distribution:\")\n",
        "    print(df[\"temp_bin\"].value_counts().sort_index())\n",
        "else:\n",
        "    print(\"\\nWarning: Cannot create temperature bins - no temperature column found\")\n",
        "\n",
        "# 2. Rain flag from numeric precipitation\n",
        "if \"precip_mm\" in df.columns:\n",
        "    # Create rain flag from numeric precipitation\n",
        "    df[\"rain_flag\"] = (df[\"precip_mm\"] > 0).astype(int)\n",
        "    print(f\"\\n✓ Created 'rain_flag' from numeric precipitation\")\n",
        "    print(f\"  Days with rain (precip > 0 mm): {df['rain_flag'].sum()}\")\n",
        "    print(f\"  Days without rain: {(df['rain_flag'] == 0).sum()}\")\n",
        "elif \"rain_flag\" in df.columns:\n",
        "    print(f\"\\n✓ Rain flag already exists (from categorical data)\")\n",
        "    print(f\"  Days with rain: {df['rain_flag'].sum()}\")\n",
        "else:\n",
        "    print(\"\\nWarning: No precipitation data available to create rain flag\")\n",
        "\n",
        "# 3. Month and Season\n",
        "if date_columns:\n",
        "    date_col = date_columns[0]\n",
        "    \n",
        "    # Extract month\n",
        "    df[\"month\"] = df[date_col].dt.month\n",
        "    print(f\"\\n✓ Created 'month' column\")\n",
        "    \n",
        "    # Create season\n",
        "    df[\"season\"] = pd.cut(\n",
        "        df[\"month\"],\n",
        "        bins=[0, 3, 6, 9, 12],\n",
        "        labels=[\"Winter\", \"Spring\", \"Summer\", \"Autumn\"],\n",
        "        include_lowest=True\n",
        "    )\n",
        "    \n",
        "    print(f\"✓ Created 'season' column\")\n",
        "    print(f\"  Seasonal distribution:\")\n",
        "    print(df[\"season\"].value_counts().sort_index())\n",
        "else:\n",
        "    print(\"\\nWarning: Cannot create month/season - no date column found\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\nNew derived columns added:\")\n",
        "derived_cols = [\"temp_bin\", \"rain_flag\", \"month\", \"season\"]\n",
        "existing_derived = [col for col in derived_cols if col in df.columns]\n",
        "for col in existing_derived:\n",
        "    print(f\"  - {col}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7a5425e",
      "metadata": {},
      "source": [
        "## Step 11: Prepare for Citi Bike Merge\n",
        "\n",
        "Prepare merge keys to join weather data with Citi Bike trip data. Since weather data is hourly:\n",
        "- **`date`**: Extract date in YYYY-MM-DD format\n",
        "- **`hour`**: Extract hour (0-23)\n",
        "\n",
        "These columns will serve as merge keys to match each bike trip with the corresponding weather conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2053d6b4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "PREPARE FOR CITI BIKE MERGE\n",
            "============================================================\n",
            "\n",
            "Date/time columns found: ['time']\n",
            "\n",
            "✓ Detected HOURLY data in column: time\n",
            "  Created 'hour' column (0-23)\n",
            "  Hour distribution (sample):\")\n",
            "hour\n",
            "0    365\n",
            "1    365\n",
            "2    365\n",
            "3    365\n",
            "4    365\n",
            "5    365\n",
            "6    365\n",
            "7    365\n",
            "8    365\n",
            "9    365\n",
            "Name: count, dtype: int64\n",
            "  Created 'date' column in YYYY-MM-DD format\n",
            "\n",
            "  Sample dates:\n",
            "  [datetime.date(2018, 1, 1), datetime.date(2018, 1, 1), datetime.date(2018, 1, 1), datetime.date(2018, 1, 1), datetime.date(2018, 1, 1), datetime.date(2018, 1, 1), datetime.date(2018, 1, 1), datetime.date(2018, 1, 1), datetime.date(2018, 1, 1), datetime.date(2018, 1, 1)]\n",
            "\n",
            "  Sample date-hour combinations:\n",
            "             date  hour\n",
            "17544  2018-01-01     0\n",
            "17545  2018-01-01     1\n",
            "17546  2018-01-01     2\n",
            "17547  2018-01-01     3\n",
            "17548  2018-01-01     4\n",
            "17549  2018-01-01     5\n",
            "17550  2018-01-01     6\n",
            "17551  2018-01-01     7\n",
            "17552  2018-01-01     8\n",
            "17553  2018-01-01     9\n",
            "\n",
            "✓ Data is now ready to merge with Citi Bike trips!\n",
            "  Merge key: 'date' (YYYY-MM-DD)\n",
            "  Optional merge key: 'date' + 'hour' for hourly analysis\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Step 9: Ensure merge compatibility with Citi Bike trips\n",
        "print(\"=\"*60)\n",
        "print(\"PREPARE FOR CITI BIKE MERGE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if date_columns:\n",
        "    date_col = date_columns[0]\n",
        "    \n",
        "    # Check if we have datetime (with time) or just date\n",
        "    # Look for columns that might contain time information\n",
        "    datetime_cols = [col for col in df.columns if 'datetime' in col or 'time' in col]\n",
        "    has_hourly_data = len(datetime_cols) > 0\n",
        "    \n",
        "    print(f\"\\nDate/time columns found: {date_columns}\")\n",
        "    \n",
        "    if has_hourly_data:\n",
        "        # Case: Dataset has hourly readings\n",
        "        print(f\"\\n✓ Detected HOURLY data in column: {date_col}\")\n",
        "        \n",
        "        # Ensure datetime format\n",
        "        if not pd.api.types.is_datetime64_any_dtype(df[date_col]):\n",
        "            df[date_col] = pd.to_datetime(df[date_col])\n",
        "        \n",
        "        # Extract hour\n",
        "        df[\"hour\"] = df[date_col].dt.hour\n",
        "        print(f\"  Created 'hour' column (0-23)\")\n",
        "        print(f\"  Hour distribution (sample):\\\")\\n{df['hour'].value_counts().sort_index().head(10)}\")\n",
        "        \n",
        "        # Extract date in YYYY-MM-DD format\n",
        "        df[\"date\"] = df[date_col].dt.date\n",
        "        print(f\"  Created 'date' column in YYYY-MM-DD format\")\n",
        "        \n",
        "    else:\n",
        "        # Case: Dataset has daily data only\n",
        "        print(f\"\\n✓ Detected DAILY data in column: {date_col}\")\n",
        "        \n",
        "        # Extract date in YYYY-MM-DD format (convert datetime to date)\n",
        "        if pd.api.types.is_datetime64_any_dtype(df[date_col]):\n",
        "            df[\"date\"] = df[date_col].dt.date\n",
        "            print(f\"  Created 'date' column in YYYY-MM-DD format\")\n",
        "        else:\n",
        "            # If it's already a date, just rename or copy\n",
        "            if date_col != \"date\":\n",
        "                df[\"date\"] = pd.to_datetime(df[date_col]).dt.date\n",
        "                print(f\"  Created 'date' column in YYYY-MM-DD format\")\n",
        "            else:\n",
        "                print(f\"  Date column already exists in correct format\")\n",
        "    \n",
        "    # Show sample of date format\n",
        "    print(f\"\\n  Sample dates:\")\n",
        "    print(f\"  {df['date'].head(10).tolist()}\")\n",
        "    \n",
        "    if \"hour\" in df.columns:\n",
        "        print(f\"\\n  Sample date-hour combinations:\")\n",
        "        print(df[[\"date\", \"hour\"]].head(10))\n",
        "    \n",
        "    print(f\"\\n✓ Data is now ready to merge with Citi Bike trips!\")\n",
        "    print(f\"  Merge key: 'date' (YYYY-MM-DD)\")\n",
        "    if \"hour\" in df.columns:\n",
        "        print(f\"  Optional merge key: 'date' + 'hour' for hourly analysis\")\n",
        "    \n",
        "else:\n",
        "    print(\"\\nWarning: No date column found - cannot prepare for merge!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "016bd716",
      "metadata": {},
      "source": [
        "## Step 12: Data Cleaning Summary\n",
        "\n",
        "Display a comprehensive summary of the cleaned weather dataset including:\n",
        "- Final shape (rows × columns)\n",
        "- All column names\n",
        "- Missing value counts per column\n",
        "- Data types\n",
        "- Preview of cleaned data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f333b255",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DATA CLEANING SUMMARY\n",
            "============================================================\n",
            "\n",
            "Final dataset shape: (8760, 19)\n",
            "\n",
            "Column names after cleaning:\n",
            "  1. time\n",
            "  2. temperature_2m_(°c)\n",
            "  3. precipitation_(mm)\n",
            "  4. rain_(mm)\n",
            "  5. cloudcover_(%)\n",
            "  6. cloudcover_low_(%)\n",
            "  7. cloudcover_mid_(%)\n",
            "  8. cloudcover_high_(%)\n",
            "  9. windspeed_10m_(km/h)\n",
            "  10. winddirection_10m_(°)\n",
            "  11. precip_mm\n",
            "  12. wind_speed\n",
            "  13. wind_kmh\n",
            "  14. temp_bin\n",
            "  15. rain_flag\n",
            "  16. month\n",
            "  17. season\n",
            "  18. hour\n",
            "  19. date\n",
            "\n",
            "Missing values in final dataset:\n",
            "time                     0\n",
            "temperature_2m_(°c)      0\n",
            "precipitation_(mm)       0\n",
            "rain_(mm)                0\n",
            "cloudcover_(%)           0\n",
            "cloudcover_low_(%)       0\n",
            "cloudcover_mid_(%)       0\n",
            "cloudcover_high_(%)      0\n",
            "windspeed_10m_(km/h)     0\n",
            "winddirection_10m_(°)    0\n",
            "precip_mm                0\n",
            "wind_speed               0\n",
            "wind_kmh                 0\n",
            "temp_bin                 0\n",
            "rain_flag                0\n",
            "month                    0\n",
            "season                   0\n",
            "hour                     0\n",
            "date                     0\n",
            "dtype: int64\n",
            "\n",
            "Data types:\n",
            "time                     datetime64[ns]\n",
            "temperature_2m_(°c)             float64\n",
            "precipitation_(mm)              float64\n",
            "rain_(mm)                       float64\n",
            "cloudcover_(%)                  float64\n",
            "cloudcover_low_(%)              float64\n",
            "cloudcover_mid_(%)              float64\n",
            "cloudcover_high_(%)             float64\n",
            "windspeed_10m_(km/h)            float64\n",
            "winddirection_10m_(°)           float64\n",
            "precip_mm                       float64\n",
            "wind_speed                      float64\n",
            "wind_kmh                        float64\n",
            "temp_bin                       category\n",
            "rain_flag                         int64\n",
            "month                             int32\n",
            "season                         category\n",
            "hour                              int32\n",
            "date                             object\n",
            "dtype: object\n",
            "\n",
            "First few rows of cleaned data:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>temperature_2m_(°c)</th>\n",
              "      <th>precipitation_(mm)</th>\n",
              "      <th>rain_(mm)</th>\n",
              "      <th>cloudcover_(%)</th>\n",
              "      <th>cloudcover_low_(%)</th>\n",
              "      <th>cloudcover_mid_(%)</th>\n",
              "      <th>cloudcover_high_(%)</th>\n",
              "      <th>windspeed_10m_(km/h)</th>\n",
              "      <th>winddirection_10m_(°)</th>\n",
              "      <th>precip_mm</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>wind_kmh</th>\n",
              "      <th>temp_bin</th>\n",
              "      <th>rain_flag</th>\n",
              "      <th>month</th>\n",
              "      <th>season</th>\n",
              "      <th>hour</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17544</th>\n",
              "      <td>2018-01-01 00:00:00</td>\n",
              "      <td>-11.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>302.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>15.127796</td>\n",
              "      <td>&lt;0°C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Winter</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17545</th>\n",
              "      <td>2018-01-01 01:00:00</td>\n",
              "      <td>-11.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.1</td>\n",
              "      <td>297.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.1</td>\n",
              "      <td>16.254334</td>\n",
              "      <td>&lt;0°C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Winter</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17546</th>\n",
              "      <td>2018-01-01 02:00:00</td>\n",
              "      <td>-11.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.3</td>\n",
              "      <td>302.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.3</td>\n",
              "      <td>19.794882</td>\n",
              "      <td>&lt;0°C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Winter</td>\n",
              "      <td>2</td>\n",
              "      <td>2018-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17547</th>\n",
              "      <td>2018-01-01 03:00:00</td>\n",
              "      <td>-12.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>307.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>22.369826</td>\n",
              "      <td>&lt;0°C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Winter</td>\n",
              "      <td>3</td>\n",
              "      <td>2018-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17548</th>\n",
              "      <td>2018-01-01 04:00:00</td>\n",
              "      <td>-12.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.3</td>\n",
              "      <td>309.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.3</td>\n",
              "      <td>23.013562</td>\n",
              "      <td>&lt;0°C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Winter</td>\n",
              "      <td>4</td>\n",
              "      <td>2018-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17549</th>\n",
              "      <td>2018-01-01 05:00:00</td>\n",
              "      <td>-12.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.1</td>\n",
              "      <td>310.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.1</td>\n",
              "      <td>22.691694</td>\n",
              "      <td>&lt;0°C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Winter</td>\n",
              "      <td>5</td>\n",
              "      <td>2018-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17550</th>\n",
              "      <td>2018-01-01 06:00:00</td>\n",
              "      <td>-12.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.8</td>\n",
              "      <td>311.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.8</td>\n",
              "      <td>22.208892</td>\n",
              "      <td>&lt;0°C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Winter</td>\n",
              "      <td>6</td>\n",
              "      <td>2018-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17551</th>\n",
              "      <td>2018-01-01 07:00:00</td>\n",
              "      <td>-12.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.8</td>\n",
              "      <td>310.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.8</td>\n",
              "      <td>20.599552</td>\n",
              "      <td>&lt;0°C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Winter</td>\n",
              "      <td>7</td>\n",
              "      <td>2018-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17552</th>\n",
              "      <td>2018-01-01 08:00:00</td>\n",
              "      <td>-12.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.3</td>\n",
              "      <td>307.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.3</td>\n",
              "      <td>18.185542</td>\n",
              "      <td>&lt;0°C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Winter</td>\n",
              "      <td>8</td>\n",
              "      <td>2018-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17553</th>\n",
              "      <td>2018-01-01 09:00:00</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.1</td>\n",
              "      <td>306.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.1</td>\n",
              "      <td>17.863674</td>\n",
              "      <td>&lt;0°C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Winter</td>\n",
              "      <td>9</td>\n",
              "      <td>2018-01-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     time  temperature_2m_(°c)  precipitation_(mm)  rain_(mm)  \\\n",
              "17544 2018-01-01 00:00:00                -11.1                 0.0        0.0   \n",
              "17545 2018-01-01 01:00:00                -11.5                 0.0        0.0   \n",
              "17546 2018-01-01 02:00:00                -11.8                 0.0        0.0   \n",
              "17547 2018-01-01 03:00:00                -12.2                 0.0        0.0   \n",
              "17548 2018-01-01 04:00:00                -12.2                 0.0        0.0   \n",
              "17549 2018-01-01 05:00:00                -12.3                 0.0        0.0   \n",
              "17550 2018-01-01 06:00:00                -12.4                 0.0        0.0   \n",
              "17551 2018-01-01 07:00:00                -12.4                 0.0        0.0   \n",
              "17552 2018-01-01 08:00:00                -12.5                 0.0        0.0   \n",
              "17553 2018-01-01 09:00:00                -13.0                 0.0        0.0   \n",
              "\n",
              "       cloudcover_(%)  cloudcover_low_(%)  cloudcover_mid_(%)  \\\n",
              "17544             0.0                 0.0                 0.0   \n",
              "17545             0.0                 0.0                 0.0   \n",
              "17546             0.0                 0.0                 0.0   \n",
              "17547             0.0                 0.0                 0.0   \n",
              "17548             0.0                 0.0                 0.0   \n",
              "17549             0.0                 0.0                 0.0   \n",
              "17550             0.0                 0.0                 0.0   \n",
              "17551             0.0                 0.0                 0.0   \n",
              "17552             0.0                 0.0                 0.0   \n",
              "17553             0.0                 0.0                 0.0   \n",
              "\n",
              "       cloudcover_high_(%)  windspeed_10m_(km/h)  winddirection_10m_(°)  \\\n",
              "17544                  0.0                   9.4                  302.0   \n",
              "17545                  0.0                  10.1                  297.0   \n",
              "17546                  0.0                  12.3                  302.0   \n",
              "17547                  0.0                  13.9                  307.0   \n",
              "17548                  0.0                  14.3                  309.0   \n",
              "17549                  0.0                  14.1                  310.0   \n",
              "17550                  0.0                  13.8                  311.0   \n",
              "17551                  0.0                  12.8                  310.0   \n",
              "17552                  0.0                  11.3                  307.0   \n",
              "17553                  0.0                  11.1                  306.0   \n",
              "\n",
              "       precip_mm  wind_speed   wind_kmh temp_bin  rain_flag  month  season  \\\n",
              "17544        0.0         9.4  15.127796     <0°C          0      1  Winter   \n",
              "17545        0.0        10.1  16.254334     <0°C          0      1  Winter   \n",
              "17546        0.0        12.3  19.794882     <0°C          0      1  Winter   \n",
              "17547        0.0        13.9  22.369826     <0°C          0      1  Winter   \n",
              "17548        0.0        14.3  23.013562     <0°C          0      1  Winter   \n",
              "17549        0.0        14.1  22.691694     <0°C          0      1  Winter   \n",
              "17550        0.0        13.8  22.208892     <0°C          0      1  Winter   \n",
              "17551        0.0        12.8  20.599552     <0°C          0      1  Winter   \n",
              "17552        0.0        11.3  18.185542     <0°C          0      1  Winter   \n",
              "17553        0.0        11.1  17.863674     <0°C          0      1  Winter   \n",
              "\n",
              "       hour        date  \n",
              "17544     0  2018-01-01  \n",
              "17545     1  2018-01-01  \n",
              "17546     2  2018-01-01  \n",
              "17547     3  2018-01-01  \n",
              "17548     4  2018-01-01  \n",
              "17549     5  2018-01-01  \n",
              "17550     6  2018-01-01  \n",
              "17551     7  2018-01-01  \n",
              "17552     8  2018-01-01  \n",
              "17553     9  2018-01-01  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Final summary of cleaned data\n",
        "print(\"=\"*60)\n",
        "print(\"DATA CLEANING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nFinal dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumn names after cleaning:\")\n",
        "for i, col in enumerate(df.columns, 1):\n",
        "    print(f\"  {i}. {col}\")\n",
        "\n",
        "print(f\"\\nMissing values in final dataset:\")\n",
        "print(df.isna().sum())\n",
        "\n",
        "print(f\"\\nData types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(f\"\\nFirst few rows of cleaned data:\")\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e22a6719",
      "metadata": {},
      "source": [
        "## Step 13: Save Cleaned Weather Data\n",
        "\n",
        "Export the cleaned weather dataset to a CSV file (`cleaned_weather_data.csv`). This file contains:\n",
        "- 8,760 hourly records for 2018\n",
        "- 19 columns including original and derived features\n",
        "- Ready for merging with Citi Bike trip data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d51f83fe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SAVING CLEANED DATA\n",
            "============================================================\n",
            "\n",
            "✓ Cleaned weather data saved successfully!\n",
            "  Filename: cleaned_weather_data.csv\n",
            "  Location: /Users/hstro/Documents/DTU/1st Semester/Introduction to business analytics/Project/Part 2\n",
            "  Rows: 8760\n",
            "  Columns: 19\n",
            "  File size: 1006.54 KB\n",
            "\n",
            "  Columns saved:\n",
            "    1. time\n",
            "    2. temperature_2m_(°c)\n",
            "    3. precipitation_(mm)\n",
            "    4. rain_(mm)\n",
            "    5. cloudcover_(%)\n",
            "    6. cloudcover_low_(%)\n",
            "    7. cloudcover_mid_(%)\n",
            "    8. cloudcover_high_(%)\n",
            "    9. windspeed_10m_(km/h)\n",
            "    10. winddirection_10m_(°)\n",
            "    11. precip_mm\n",
            "    12. wind_speed\n",
            "    13. wind_kmh\n",
            "    14. temp_bin\n",
            "    15. rain_flag\n",
            "    16. month\n",
            "    17. season\n",
            "    18. hour\n",
            "    19. date\n",
            "\n",
            "============================================================\n",
            "Data cleaning complete! Ready to merge with Citi Bike data.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Save the cleaned data to CSV file\n",
        "print(\"=\"*60)\n",
        "print(\"SAVING CLEANED DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "output_filename = \"cleaned_weather_data.csv\"\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"\\n✓ Cleaned weather data saved successfully!\")\n",
        "print(f\"  Filename: {output_filename}\")\n",
        "print(f\"  Location: {os.getcwd()}\")\n",
        "print(f\"  Rows: {len(df)}\")\n",
        "print(f\"  Columns: {len(df.columns)}\")\n",
        "print(f\"  File size: {os.path.getsize(output_filename) / 1024:.2f} KB\")\n",
        "\n",
        "print(f\"\\n  Columns saved:\")\n",
        "for i, col in enumerate(df.columns, 1):\n",
        "    print(f\"    {i}. {col}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Data cleaning complete! Ready to merge with Citi Bike data.\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78a65c33",
      "metadata": {},
      "source": [
        "## Sanity Check - Merged Dataset\n",
        "\n",
        "Now let's perform sanity checks on the merged dataset to verify the merge was successful and data quality is maintained."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5decd66",
      "metadata": {},
      "source": [
        "## Load and Prepare Citi Bike Data for Merging\n",
        "\n",
        "Now we'll load the Citi Bike trip data and prepare it for merging with the weather data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c595aaf",
      "metadata": {},
      "source": [
        "### Load All Citi Bike CSV Files\n",
        "\n",
        "Load all 2018 Citi Bike trip data CSV files from the local directory. This cell:\n",
        "- Finds all CSV files containing \"2018\" in the filename\n",
        "- Loads each file into a DataFrame\n",
        "- Concatenates all DataFrames into a single dataset (~18.8 million trips)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "57c69605",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "LOADING CITI BIKE DATA\n",
            "============================================================\n",
            "\n",
            "Found 14 Citi Bike CSV files\n",
            "Sample files: ['../2018-citibike-tripdata/201809-citibike-tripdata.csv', '../2018-citibike-tripdata/201801-citibike-tripdata.csv', '../2018-citibike-tripdata/201803-citibike-tripdata.csv']\n",
            "\n",
            "Loading Citi Bike data...\n",
            "\n",
            "✓ Loaded Citi Bike data\n",
            "  Shape: (18855882, 15)\n",
            "  Columns: ['tripduration', 'starttime', 'stoptime', 'start station id', 'start station name', 'start station latitude', 'start station longitude', 'end station id', 'end station name', 'end station latitude', 'end station longitude', 'bikeid', 'usertype', 'birth year', 'gender']\n",
            "\n",
            "First few rows:\n",
            "   tripduration                 starttime                  stoptime  \\\n",
            "0          1635  2018-09-01 00:00:05.2690  2018-09-01 00:27:20.6340   \n",
            "1           132  2018-09-01 00:00:11.2810  2018-09-01 00:02:23.4810   \n",
            "2          3337  2018-09-01 00:00:20.6490  2018-09-01 00:55:58.5470   \n",
            "3           436  2018-09-01 00:00:21.7460  2018-09-01 00:07:38.5830   \n",
            "4          8457  2018-09-01 00:00:27.3150  2018-09-01 02:21:25.3080   \n",
            "\n",
            "   start station id               start station name  start station latitude  \\\n",
            "0             252.0     MacDougal St & Washington Sq               40.732264   \n",
            "1             314.0  Cadman Plaza West & Montague St               40.693830   \n",
            "2            3142.0                  1 Ave & E 62 St               40.761227   \n",
            "3             308.0          St James Pl & Oliver St               40.713079   \n",
            "4             345.0                  W 13 St & 6 Ave               40.736494   \n",
            "\n",
            "   start station longitude  end station id            end station name  \\\n",
            "0               -73.998522           366.0    Clinton Ave & Myrtle Ave   \n",
            "1               -73.990539          3242.0  Schermerhorn St & Court St   \n",
            "2               -73.960940          3384.0             Smith St & 3 St   \n",
            "3               -73.998512          3690.0         Park Pl & Church St   \n",
            "4               -73.997044           380.0            W 4 St & 7 Ave S   \n",
            "\n",
            "   end station latitude  end station longitude  bikeid    usertype  \\\n",
            "0             40.693261             -73.968896   25577  Subscriber   \n",
            "1             40.691029             -73.991834   34377  Subscriber   \n",
            "2             40.678724             -73.995991   30496  Subscriber   \n",
            "3             40.713342             -74.009355   28866  Subscriber   \n",
            "4             40.734011             -74.002939   20943    Customer   \n",
            "\n",
            "   birth year  gender  \n",
            "0        1980       1  \n",
            "1        1969       0  \n",
            "2        1975       1  \n",
            "3        1984       2  \n",
            "4        1994       1  \n"
          ]
        }
      ],
      "source": [
        "# Load Citi Bike trip data\n",
        "print(\"=\"*60)\n",
        "print(\"LOADING CITI BIKE DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Path to Citi Bike data directory\n",
        "citibike_path = \"../2018-citibike-tripdata/\"\n",
        "\n",
        "# Get all CSV files in the directory\n",
        "import glob\n",
        "csv_files = glob.glob(os.path.join(citibike_path, \"*.csv\"))\n",
        "\n",
        "# Filter for 2018 files only (should already be filtered by directory)\n",
        "csv_files = [f for f in csv_files if \"2018\" in f]\n",
        "\n",
        "print(f\"\\nFound {len(csv_files)} Citi Bike CSV files\")\n",
        "print(f\"Sample files: {csv_files[:3]}\")\n",
        "\n",
        "# Load all CSV files and concatenate\n",
        "print(\"\\nLoading Citi Bike data...\")\n",
        "citibike_dfs = []\n",
        "for file in csv_files:\n",
        "    temp_df = pd.read_csv(file)\n",
        "    citibike_dfs.append(temp_df)\n",
        "    \n",
        "citibike_df = pd.concat(citibike_dfs, ignore_index=True)\n",
        "\n",
        "print(f\"\\n✓ Loaded Citi Bike data\")\n",
        "print(f\"  Shape: {citibike_df.shape}\")\n",
        "print(f\"  Columns: {citibike_df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(citibike_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bbe1014",
      "metadata": {},
      "source": [
        "### Prepare Citi Bike Data for Merging\n",
        "\n",
        "Extract merge keys from Citi Bike trip data:\n",
        "- **`date`**: Extract date from `starttime` column\n",
        "- **`hour`**: Extract hour from `starttime` column\n",
        "\n",
        "These keys will match each trip to the corresponding hourly weather data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "678629a8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "PREPARING CITI BIKE DATA FOR MERGE\n",
            "============================================================\n",
            "\n",
            "Time column found: starttime\n",
            "\n",
            "✓ Created 'date' and 'hour' columns for merging\n",
            "  Date range: 2018-01-01 to 2018-12-31\n",
            "  Hour range: 0 to 23\n",
            "\n",
            "Sample date-hour combinations:\n",
            "         date  hour\n",
            "0  2018-09-01     0\n",
            "1  2018-09-01     0\n",
            "2  2018-09-01     0\n",
            "3  2018-09-01     0\n",
            "4  2018-09-01     0\n",
            "5  2018-09-01     0\n",
            "6  2018-09-01     0\n",
            "7  2018-09-01     0\n",
            "8  2018-09-01     0\n",
            "9  2018-09-01     0\n"
          ]
        }
      ],
      "source": [
        "# Prepare Citi Bike data for merging with weather data\n",
        "print(\"=\"*60)\n",
        "print(\"PREPARING CITI BIKE DATA FOR MERGE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Find the start time column (could be 'starttime', 'start time', 'Start Time', etc.)\n",
        "time_cols = [col for col in citibike_df.columns if 'start' in col.lower() and 'time' in col.lower()]\n",
        "if not time_cols:\n",
        "    time_cols = [col for col in citibike_df.columns if 'time' in col.lower()]\n",
        "\n",
        "print(f\"\\nTime column found: {time_cols[0]}\")\n",
        "\n",
        "# Convert start time to datetime\n",
        "start_time_col = time_cols[0]\n",
        "citibike_df[start_time_col] = pd.to_datetime(citibike_df[start_time_col])\n",
        "\n",
        "# Extract date and hour for merging\n",
        "citibike_df['date'] = citibike_df[start_time_col].dt.date\n",
        "citibike_df['hour'] = citibike_df[start_time_col].dt.hour\n",
        "\n",
        "print(f\"\\n✓ Created 'date' and 'hour' columns for merging\")\n",
        "print(f\"  Date range: {citibike_df['date'].min()} to {citibike_df['date'].max()}\")\n",
        "print(f\"  Hour range: {citibike_df['hour'].min()} to {citibike_df['hour'].max()}\")\n",
        "print(f\"\\nSample date-hour combinations:\")\n",
        "print(citibike_df[['date', 'hour']].head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d93a3b42",
      "metadata": {},
      "source": [
        "### Merge Citi Bike and Weather Data\n",
        "\n",
        "Perform a **LEFT JOIN** to merge Citi Bike trips with weather data using `date` and `hour` as keys. This preserves all Citi Bike trips while adding weather columns to each row. The merge adds weather conditions (temperature, precipitation, wind) to each trip based on when it started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "286fb493",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MERGING CITI BIKE WITH WEATHER DATA\n",
            "============================================================\n",
            "\n",
            "Before merge:\n",
            "  Citi Bike data: (18855882, 17)\n",
            "  Weather data: (8760, 19)\n",
            "\n",
            "✓ Merge completed!\n",
            "  Merged dataset shape: (18855882, 34)\n",
            "  Merge type: LEFT JOIN (keep all Citi Bike trips)\n",
            "  Merge keys: ['date', 'hour']\n",
            "\n",
            "  Trips with weather data: 18,855,882 (100.0%)\n",
            "  Trips without weather data: 0\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Merge Citi Bike data with weather data\n",
        "print(\"=\"*60)\n",
        "print(\"MERGING CITI BIKE WITH WEATHER DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# The cleaned weather data is in 'df' variable\n",
        "# Ensure both date columns are the same type for merging\n",
        "weather_df = df.copy()\n",
        "\n",
        "print(f\"\\nBefore merge:\")\n",
        "print(f\"  Citi Bike data: {citibike_df.shape}\")\n",
        "print(f\"  Weather data: {weather_df.shape}\")\n",
        "\n",
        "# Merge on both date and hour\n",
        "merged = citibike_df.merge(\n",
        "    weather_df,\n",
        "    on=['date', 'hour'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Merge completed!\")\n",
        "print(f\"  Merged dataset shape: {merged.shape}\")\n",
        "print(f\"  Merge type: LEFT JOIN (keep all Citi Bike trips)\")\n",
        "print(f\"  Merge keys: ['date', 'hour']\")\n",
        "\n",
        "# Check how many rows have weather data\n",
        "weather_matched = merged['temperature_2m_(°c)'].notna().sum()\n",
        "print(f\"\\n  Trips with weather data: {weather_matched:,} ({weather_matched/len(merged)*100:.1f}%)\")\n",
        "print(f\"  Trips without weather data: {merged['temperature_2m_(°c)'].isna().sum():,}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "162e715d",
      "metadata": {},
      "source": [
        "### Sanity Check: Verify Merged Dataset Shape\n",
        "\n",
        "Verify the merge was successful by checking the dataset dimensions. The merged dataset should have:\n",
        "- Same number of rows as original Citi Bike data\n",
        "- Combined columns from both datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f0b9f5ce",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MERGED DATASET SHAPE\n",
            "============================================================\n",
            "\n",
            "Shape of merged dataset: (18855882, 34)\n",
            "  Rows: 18,855,882\n",
            "  Columns: 34\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Sanity Check 1: Check the shape of the merged dataset\n",
        "print(\"=\"*60)\n",
        "print(\"MERGED DATASET SHAPE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nShape of merged dataset: {merged.shape}\")\n",
        "print(f\"  Rows: {merged.shape[0]:,}\")\n",
        "print(f\"  Columns: {merged.shape[1]}\")\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd17d485",
      "metadata": {},
      "source": [
        "### Sanity Check: Preview Merged Data\n",
        "\n",
        "Display a sample of the merged dataset showing key columns (date, hour, temperature, rain flag, wind speed) to verify the weather data was correctly matched to trips."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5b910578",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SAMPLE OF MERGED DATASET\n",
            "============================================================\n",
            "\n",
            "First 10 rows of key columns:\n",
            "         date  hour  temperature_2m_(°c)  rain_flag  wind_kmh\n",
            "0  2018-09-01     0                 22.1          1   16.0934\n",
            "1  2018-09-01     0                 22.1          1   16.0934\n",
            "2  2018-09-01     0                 22.1          1   16.0934\n",
            "3  2018-09-01     0                 22.1          1   16.0934\n",
            "4  2018-09-01     0                 22.1          1   16.0934\n",
            "5  2018-09-01     0                 22.1          1   16.0934\n",
            "6  2018-09-01     0                 22.1          1   16.0934\n",
            "7  2018-09-01     0                 22.1          1   16.0934\n",
            "8  2018-09-01     0                 22.1          1   16.0934\n",
            "9  2018-09-01     0                 22.1          1   16.0934\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Sanity Check 2: Display head of key columns\n",
        "print(\"=\"*60)\n",
        "print(\"SAMPLE OF MERGED DATASET\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nFirst 10 rows of key columns:\")\n",
        "print(merged[[\"date\", \"hour\", \"temperature_2m_(°c)\", \"rain_flag\", \"wind_kmh\"]].head(10))\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba93ec50",
      "metadata": {},
      "source": [
        "### Sanity Check: Missing Value Analysis\n",
        "\n",
        "Check for missing values in key weather columns after the merge. If any trips couldn't be matched with weather data, they will have NaN values. Drop these rows to ensure complete data for modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d2a16c86",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MISSING VALUE ANALYSIS\n",
            "============================================================\n",
            "\n",
            "Proportion of missing values in key weather columns:\n",
            "temperature_2m_(°c)    0.0\n",
            "rain_flag              0.0\n",
            "wind_kmh               0.0\n",
            "dtype: float64\n",
            "\n",
            "Summary:\n",
            "  Temperature missing: 0.00%\n",
            "  Rain flag missing: 0.00%\n",
            "  Wind speed missing: 0.00%\n",
            "\n",
            "✓ No rows with missing weather data - all trips have complete weather information!\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Sanity Check 3: Check for missing values in key weather columns\n",
        "print(\"=\"*60)\n",
        "print(\"MISSING VALUE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nProportion of missing values in key weather columns:\")\n",
        "missing_props = merged[[\"temperature_2m_(°c)\", \"rain_flag\", \"wind_kmh\"]].isna().mean()\n",
        "print(missing_props)\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  Temperature missing: {missing_props['temperature_2m_(°c)']*100:.2f}%\")\n",
        "print(f\"  Rain flag missing: {missing_props['rain_flag']*100:.2f}%\")\n",
        "print(f\"  Wind speed missing: {missing_props['wind_kmh']*100:.2f}%\")\n",
        "\n",
        "# Drop rows with missing weather data\n",
        "before_drop = len(merged)\n",
        "merged = merged.dropna(subset=[\"temperature_2m_(°c)\", \"rain_flag\", \"wind_kmh\"])\n",
        "after_drop = len(merged)\n",
        "\n",
        "if before_drop > after_drop:\n",
        "    print(f\"\\n✓ Dropped {before_drop - after_drop:,} rows with missing weather data\")\n",
        "    print(f\"  Remaining rows: {after_drop:,}\")\n",
        "else:\n",
        "    print(f\"\\n✓ No rows with missing weather data - all trips have complete weather information!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb0baacd",
      "metadata": {},
      "source": [
        "## Create Clean Modeling Dataset\n",
        "\n",
        "Now let's create a clean dataset ready for modeling by adding useful features and filtering out unreasonable trips."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4a591241",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "CREATING MODELING DATASET\n",
            "============================================================\n",
            "\n",
            "Starting with 18,855,882 trips\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"CREATING MODELING DATASET\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create a copy of the merged dataset\n",
        "df = merged.copy()\n",
        "\n",
        "print(f\"\\nStarting with {len(df):,} trips\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72561f7e",
      "metadata": {},
      "source": [
        "### Initialize Modeling Dataset\n",
        "\n",
        "Create a working copy of the merged dataset for further feature engineering. This copy will be transformed into the final modeling dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d1976bb1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TRIP DURATION\n",
            "============================================================\n",
            "\n",
            "Trip duration statistics (in minutes):\n",
            "  Mean: 16.46 min\n",
            "  Median: 10.07 min\n",
            "  Min: 1.02 min\n",
            "  Max: 325167.48 min\n",
            "  Std: 316.62 min\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Convert trip duration from seconds to minutes\n",
        "df[\"trip_duration_min\"] = df[\"tripduration\"] / 60\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRIP DURATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nTrip duration statistics (in minutes):\")\n",
        "print(f\"  Mean: {df['trip_duration_min'].mean():.2f} min\")\n",
        "print(f\"  Median: {df['trip_duration_min'].median():.2f} min\")\n",
        "print(f\"  Min: {df['trip_duration_min'].min():.2f} min\")\n",
        "print(f\"  Max: {df['trip_duration_min'].max():.2f} min\")\n",
        "print(f\"  Std: {df['trip_duration_min'].std():.2f} min\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9c1656c",
      "metadata": {},
      "source": [
        "### Convert Trip Duration to Minutes\n",
        "\n",
        "Convert trip duration from seconds (original format) to minutes for easier interpretation. Display statistics including mean, median, min, max, and standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "88a05bb2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "FILTERING UNREASONABLE TRIPS\n",
            "============================================================\n",
            "\n",
            "Filtered trips outside 1-120 minute range:\n",
            "  Before: 18,855,882 trips\n",
            "  After: 18,799,954 trips\n",
            "  Removed: 55,928 trips (0.30%)\n",
            "\n",
            "New trip duration statistics (in minutes):\n",
            "  Mean: 13.40 min\n",
            "  Median: 10.03 min\n",
            "  Min: 1.02 min\n",
            "  Max: 120.00 min\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Keep only reasonable trips (1-120 minutes)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FILTERING UNREASONABLE TRIPS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "before_filter = len(df)\n",
        "df = df[(df[\"trip_duration_min\"] >= 1) & (df[\"trip_duration_min\"] <= 120)]\n",
        "after_filter = len(df)\n",
        "\n",
        "print(f\"\\nFiltered trips outside 1-120 minute range:\")\n",
        "print(f\"  Before: {before_filter:,} trips\")\n",
        "print(f\"  After: {after_filter:,} trips\")\n",
        "print(f\"  Removed: {before_filter - after_filter:,} trips ({(before_filter - after_filter)/before_filter*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\nNew trip duration statistics (in minutes):\")\n",
        "print(f\"  Mean: {df['trip_duration_min'].mean():.2f} min\")\n",
        "print(f\"  Median: {df['trip_duration_min'].median():.2f} min\")\n",
        "print(f\"  Min: {df['trip_duration_min'].min():.2f} min\")\n",
        "print(f\"  Max: {df['trip_duration_min'].max():.2f} min\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db997286",
      "metadata": {},
      "source": [
        "### Filter Unreasonable Trip Durations\n",
        "\n",
        "Remove trips with unrealistic durations:\n",
        "- **Minimum**: 1 minute (trips shorter are likely errors/cancellations)\n",
        "- **Maximum**: 120 minutes (2 hours - trips longer are statistical outliers)\n",
        "\n",
        "This removes approximately 0.3% of trips and ensures data quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "46366419",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "LOG DURATION\n",
            "============================================================\n",
            "\n",
            "Log duration statistics:\n",
            "  Mean: 2.3111\n",
            "  Median: 2.3059\n",
            "  Min: 0.0165\n",
            "  Max: 4.7875\n",
            "  Std: 0.7642\n",
            "\n",
            "✓ Created 'log_duration' for regression modeling\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Create log-transformed duration for regression\n",
        "df[\"log_duration\"] = np.log(df[\"trip_duration_min\"])\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LOG DURATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nLog duration statistics:\")\n",
        "print(f\"  Mean: {df['log_duration'].mean():.4f}\")\n",
        "print(f\"  Median: {df['log_duration'].median():.4f}\")\n",
        "print(f\"  Min: {df['log_duration'].min():.4f}\")\n",
        "print(f\"  Max: {df['log_duration'].max():.4f}\")\n",
        "print(f\"  Std: {df['log_duration'].std():.4f}\")\n",
        "\n",
        "print(f\"\\n✓ Created 'log_duration' for regression modeling\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65e042ae",
      "metadata": {},
      "source": [
        "### Create Log-Transformed Duration\n",
        "\n",
        "Apply natural logarithm transformation to trip duration. Log transformation is useful for:\n",
        "- Normalizing right-skewed duration distribution\n",
        "- Improving regression model performance\n",
        "- Stabilizing variance across different duration ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "85392157",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TIME FEATURES\n",
            "============================================================\n",
            "\n",
            "✓ Created time-based features:\n",
            "  'weekday': Day of week (0=Monday, 6=Sunday)\n",
            "  'is_weekend': Binary flag for weekend trips\n",
            "\n",
            "Weekday distribution:\n",
            "  Monday: 2,716,653 trips (14.5%)\n",
            "  Tuesday: 2,865,435 trips (15.2%)\n",
            "  Wednesday: 2,899,018 trips (15.4%)\n",
            "  Thursday: 2,929,111 trips (15.6%)\n",
            "  Friday: 2,780,371 trips (14.8%)\n",
            "  Saturday: 2,453,795 trips (13.1%)\n",
            "  Sunday: 2,155,571 trips (11.5%)\n",
            "\n",
            "Weekend vs Weekday:\n",
            "  Weekday trips: 14,190,588 (75.5%)\n",
            "  Weekend trips: 4,609,366 (24.5%)\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Create weekday and weekend features\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TIME FEATURES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Extract weekday (0=Monday, 6=Sunday)\n",
        "df[\"weekday\"] = df[\"starttime\"].dt.weekday\n",
        "\n",
        "# Create weekend flag (Saturday=5, Sunday=6)\n",
        "df[\"is_weekend\"] = (df[\"weekday\"] >= 5).astype(int)\n",
        "\n",
        "print(f\"\\n✓ Created time-based features:\")\n",
        "print(f\"  'weekday': Day of week (0=Monday, 6=Sunday)\")\n",
        "print(f\"  'is_weekend': Binary flag for weekend trips\")\n",
        "\n",
        "print(f\"\\nWeekday distribution:\")\n",
        "weekday_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "for i, name in enumerate(weekday_names):\n",
        "    count = (df['weekday'] == i).sum()\n",
        "    print(f\"  {name}: {count:,} trips ({count/len(df)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nWeekend vs Weekday:\")\n",
        "print(f\"  Weekday trips: {(df['is_weekend'] == 0).sum():,} ({(df['is_weekend'] == 0).sum()/len(df)*100:.1f}%)\")\n",
        "print(f\"  Weekend trips: {(df['is_weekend'] == 1).sum():,} ({(df['is_weekend'] == 1).sum()/len(df)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10ee7565",
      "metadata": {},
      "source": [
        "### Create Time-Based Features\n",
        "\n",
        "Extract temporal features from trip start time:\n",
        "- **`weekday`**: Day of week (0=Monday to 6=Sunday)\n",
        "- **`is_weekend`**: Binary indicator (1=Saturday/Sunday, 0=weekday)\n",
        "\n",
        "These features capture weekly patterns in bike usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7ee209e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "MODELING DATASET SUMMARY\n",
            "============================================================\n",
            "\n",
            "Final dataset shape: (18799954, 38)\n",
            "  Rows: 18,799,954\n",
            "  Columns: 38\n",
            "\n",
            "Key features available:\n",
            "\n",
            "  Duration features:\n",
            "    - trip_duration_min: Trip duration in minutes\n",
            "    - log_duration: Log-transformed duration for regression\n",
            "\n",
            "  Weather features:\n",
            "    - temperature_2m_(°c): Temperature in Celsius\n",
            "    - rain_flag: Binary indicator for rain\n",
            "    - wind_kmh: Wind speed in km/h\n",
            "\n",
            "  Time features:\n",
            "    - date: Date of trip\n",
            "    - hour: Hour of day (0-23)\n",
            "    - weekday: Day of week (0-6)\n",
            "    - is_weekend: Weekend indicator (0/1)\n",
            "\n",
            "✓ Dataset is ready for modeling!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Summary of the modeling dataset\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODELING DATASET SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nFinal dataset shape: {df.shape}\")\n",
        "print(f\"  Rows: {df.shape[0]:,}\")\n",
        "print(f\"  Columns: {df.shape[1]}\")\n",
        "\n",
        "print(f\"\\nKey features available:\")\n",
        "print(f\"\\n  Duration features:\")\n",
        "print(f\"    - trip_duration_min: Trip duration in minutes\")\n",
        "print(f\"    - log_duration: Log-transformed duration for regression\")\n",
        "\n",
        "print(f\"\\n  Weather features:\")\n",
        "print(f\"    - temperature_2m_(°c): Temperature in Celsius\")\n",
        "print(f\"    - rain_flag: Binary indicator for rain\")\n",
        "print(f\"    - wind_kmh: Wind speed in km/h\")\n",
        "\n",
        "print(f\"\\n  Time features:\")\n",
        "print(f\"    - date: Date of trip\")\n",
        "print(f\"    - hour: Hour of day (0-23)\")\n",
        "print(f\"    - weekday: Day of week (0-6)\")\n",
        "print(f\"    - is_weekend: Weekend indicator (0/1)\")\n",
        "\n",
        "print(f\"\\n✓ Dataset is ready for modeling!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2bcb3f0",
      "metadata": {},
      "source": [
        "### Modeling Dataset Summary\n",
        "\n",
        "Display final summary of the prepared modeling dataset including:\n",
        "- Dataset dimensions\n",
        "- Available features grouped by category (duration, weather, time)\n",
        "- Confirmation that dataset is ready for model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "263a72b7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample of modeling dataset with key features:\n",
            "          date  hour  weekday  is_weekend  trip_duration_min  log_duration  \\\n",
            "0   2018-09-01     0        5           1          27.250000      3.305054   \n",
            "1   2018-09-01     0        5           1           2.200000      0.788457   \n",
            "2   2018-09-01     0        5           1          55.616667      4.018483   \n",
            "3   2018-09-01     0        5           1           7.266667      1.983298   \n",
            "5   2018-09-01     0        5           1          55.433333      4.015181   \n",
            "6   2018-09-01     0        5           1           3.883333      1.356694   \n",
            "7   2018-09-01     0        5           1           4.750000      1.558145   \n",
            "8   2018-09-01     0        5           1          18.783333      2.932970   \n",
            "9   2018-09-01     0        5           1           7.050000      1.953028   \n",
            "10  2018-09-01     0        5           1           5.450000      1.695616   \n",
            "\n",
            "    temperature_2m_(°c)  rain_flag  wind_kmh  \n",
            "0                  22.1          1   16.0934  \n",
            "1                  22.1          1   16.0934  \n",
            "2                  22.1          1   16.0934  \n",
            "3                  22.1          1   16.0934  \n",
            "5                  22.1          1   16.0934  \n",
            "6                  22.1          1   16.0934  \n",
            "7                  22.1          1   16.0934  \n",
            "8                  22.1          1   16.0934  \n",
            "9                  22.1          1   16.0934  \n",
            "10                 22.1          1   16.0934  \n"
          ]
        }
      ],
      "source": [
        "# Display sample of the modeling dataset\n",
        "print(\"\\nSample of modeling dataset with key features:\")\n",
        "key_cols = ['date', 'hour', 'weekday', 'is_weekend', 'trip_duration_min', 'log_duration', \n",
        "            'temperature_2m_(°c)', 'rain_flag', 'wind_kmh']\n",
        "# Only select columns that exist\n",
        "key_cols_existing = [col for col in key_cols if col in df.columns]\n",
        "print(df[key_cols_existing].head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da102464",
      "metadata": {},
      "source": [
        "### Preview Modeling Dataset\n",
        "\n",
        "Display sample rows of the final modeling dataset showing key feature columns to verify all transformations were applied correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9d6be41",
      "metadata": {},
      "source": [
        "## Save Modeling Dataset\n",
        "\n",
        "The modeling dataset is now ready. We'll save it for use in the next notebook (scriptp2.ipynb) where we'll build and train the prediction model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "d6e04afb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SAVING MODELING DATASET\n",
            "============================================================\n",
            "\n",
            "✓ Modeling dataset saved successfully!\n",
            "  Filename: modeling_dataset.csv\n",
            "  Location: /Users/hstro/Documents/DTU/1st Semester/Introduction to business analytics/Project/Part 2\n",
            "  Rows: 18,799,954\n",
            "  Columns: 38\n",
            "\n",
            "  Key columns saved:\n",
            "    - Trip data: tripduration, trip_duration_min, log_duration\n",
            "    - Weather: temperature_2m_(°c), rain_flag, wind_kmh\n",
            "    - Time: date, hour, weekday, is_weekend\n",
            "\n",
            "============================================================\n",
            "✅ DATA CLEANING COMPLETE!\n",
            "============================================================\n",
            "\n",
            "Next steps:\n",
            "  → Open 'scriptp2.ipynb' to build and train the prediction model\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Save the modeling dataset to CSV\n",
        "print(\"=\"*60)\n",
        "print(\"SAVING MODELING DATASET\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "output_filename = \"modeling_dataset.csv\"\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"\\n✓ Modeling dataset saved successfully!\")\n",
        "print(f\"  Filename: {output_filename}\")\n",
        "print(f\"  Location: {os.getcwd()}\")\n",
        "print(f\"  Rows: {len(df):,}\")\n",
        "print(f\"  Columns: {len(df.columns)}\")\n",
        "\n",
        "print(f\"\\n  Key columns saved:\")\n",
        "print(f\"    - Trip data: tripduration, trip_duration_min, log_duration\")\n",
        "print(f\"    - Weather: temperature_2m_(°c), rain_flag, wind_kmh\")\n",
        "print(f\"    - Time: date, hour, weekday, is_weekend\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅ DATA CLEANING COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"  → Open 'scriptp2.ipynb' to build and train the prediction model\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
